{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 1024)\nimport matplotlib.pyplot as plt\nimport random\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,Flatten ,GlobalAveragePooling2D, BatchNormalization, Dropout, Dense\n# from keras.optimizers import RMSprop\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.utils import to_categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n%matplotlib inline\n\nfrom pathlib import Path\n\n\n## tensorflow & Keras\nimport tensorflow as tf  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-04T13:21:10.687530Z","iopub.execute_input":"2021-11-04T13:21:10.687783Z","iopub.status.idle":"2021-11-04T13:21:10.697657Z","shell.execute_reply.started":"2021-11-04T13:21:10.687759Z","shell.execute_reply":"2021-11-04T13:21:10.696806Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/train.csv')\ntrain_images = Path(r'../input/arabic-hwr-ai-pro-intake1/train')\n\ntest_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/test.csv')\ntest_images = Path(r'../input/arabic-hwr-ai-pro-intake1/tets')\n## read these all training images paths as Series\ntrain_images_paths = pd.Series(sorted(list(train_images.glob(r'*.png'))), name='Filepath').astype(str)\ntrain_images_paths.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T13:21:15.131949Z","iopub.execute_input":"2021-11-04T13:21:15.132226Z","iopub.status.idle":"2021-11-04T13:21:15.319897Z","shell.execute_reply.started":"2021-11-04T13:21:15.132197Z","shell.execute_reply":"2021-11-04T13:21:15.318702Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0    ../input/arabic-hwr-ai-pro-intake1/train/00000...\n1    ../input/arabic-hwr-ai-pro-intake1/train/00001...\n2    ../input/arabic-hwr-ai-pro-intake1/train/00002...\n3    ../input/arabic-hwr-ai-pro-intake1/train/00003...\n4    ../input/arabic-hwr-ai-pro-intake1/train/00004...\nName: Filepath, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"import cv2 \nimg = cv2.imread(train_images_paths.iloc[29])[:,:,:3]\n# img = cv2.dilate(img,(5,5)) \n# img3_gr = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n\n# im_e,binary = cv2.threshold(img3_gr,100,100,cv2.THRESH_BINARY_INV)\n# binary.reshape(32,32,1).shape\nplt.imshow(img)\n# plt.imshow(img)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T13:21:18.754127Z","iopub.execute_input":"2021-11-04T13:21:18.755329Z","iopub.status.idle":"2021-11-04T13:21:18.968960Z","shell.execute_reply.started":"2021-11-04T13:21:18.755297Z","shell.execute_reply":"2021-11-04T13:21:18.968103Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7fbbed0d8090>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"\n# plt.imshow(train_full_set[29],cmap='gray')\n# # train_labels['label'][29]\n# # train_full_set[0].shape","metadata":{"execution":{"iopub.status.busy":"2021-10-27T19:33:33.564871Z","iopub.execute_input":"2021-10-27T19:33:33.565665Z","iopub.status.idle":"2021-10-27T19:33:33.787696Z","shell.execute_reply.started":"2021-10-27T19:33:33.56562Z","shell.execute_reply":"2021-10-27T19:33:33.787006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_key_value = {}\nfor value in train_labels['label'].unique():\n    img_key_value[value] = train_labels[train_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {img_label[i]}')\n        img = plt.imread(train_images_paths.iloc[img_index[i]])\n        plt.imshow(img[:,:,:3])\n        plt.axis('off')\n        i+=1","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:31:23.027333Z","iopub.execute_input":"2021-11-01T13:31:23.027641Z","iopub.status.idle":"2021-11-01T13:31:24.59242Z","shell.execute_reply.started":"2021-11-01T13:31:23.027609Z","shell.execute_reply":"2021-11-01T13:31:24.591496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of Instances in train_set =>', len(train_images_paths))\nprint('Number of Instances in train_labels =>', len(train_labels))\n\n\nprint(train_images_paths.shape[0])\n\nimg = plt.imread(train_images_paths.iloc[img_index[0]])\nprint('shape of each Image is =>', img.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:31:29.430141Z","iopub.execute_input":"2021-11-01T13:31:29.430435Z","iopub.status.idle":"2021-11-01T13:31:29.438348Z","shell.execute_reply.started":"2021-11-01T13:31:29.430384Z","shell.execute_reply":"2021-11-01T13:31:29.437696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-25T19:06:02.92664Z","iopub.execute_input":"2021-10-25T19:06:02.926971Z","iopub.status.idle":"2021-10-25T19:06:02.934894Z","shell.execute_reply.started":"2021-10-25T19:06:02.926939Z","shell.execute_reply":"2021-10-25T19:06:02.933829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_full_labels = train_labels['label'].values\ntrain_full_set = np.empty((train_images_paths.shape[0], 32, 32,3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(train_images_paths):\n    img = cv2.imread(path)\n    img = img[:,:,:3]\n#     img = cv2.dilate(img,(5,5)) \n#     img3_gr = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n#     im_e,binary = cv2.threshold(img3_gr,100,100,cv2.THRESH_BINARY_INV)\n#     img = img/img.max()\n    train_full_set[idx] = img\n    \nprint('train_full_set.shape =>', train_full_set.shape)\nprint('train_full_labels.shape =>', train_full_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T13:21:48.423314Z","iopub.execute_input":"2021-11-04T13:21:48.423570Z","iopub.status.idle":"2021-11-04T13:22:59.036606Z","shell.execute_reply.started":"2021-11-04T13:21:48.423546Z","shell.execute_reply":"2021-11-04T13:22:59.035674Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"train_full_set.shape => (13440, 32, 32, 3)\ntrain_full_labels.shape => (13440,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# import numpy as np\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n\n# def rgb2gray(rgb):\n#     return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\n# img = mpimg.imread(train_images_paths[0])[:,:,:3]     \n# gray = rgb2gray(img)    \n# plt.imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n# plt.show()\n# img.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-03T15:15:16.189904Z","iopub.execute_input":"2021-11-03T15:15:16.190277Z","iopub.status.idle":"2021-11-03T15:15:16.195462Z","shell.execute_reply.started":"2021-11-03T15:15:16.190239Z","shell.execute_reply":"2021-11-03T15:15:16.194381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_full_set, train_full_labels, \n                                                      test_size=0.2, shuffle=True, random_state=42)\n\nprint('X_train.shape =>', X_train.shape)\nprint('X_valid.shape =>', X_valid.shape)\nprint('y_train.shape =>', y_train.shape)\nprint('y_valid.shape =>', y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T14:32:52.021137Z","iopub.execute_input":"2021-10-27T14:32:52.021447Z","iopub.status.idle":"2021-10-27T14:32:52.178508Z","shell.execute_reply.started":"2021-10-27T14:32:52.021417Z","shell.execute_reply":"2021-10-27T14:32:52.177569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder(input_img):\n    #encoder\n    #input = 28 x 28 x 1 (wide and thin)\n    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img) #28 x 28 x 32\n#     conv1 =  Dropout(0.2)(conv1)\n    conv1 = BatchNormalization()(conv1)\n#     conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n#     conv1 = BatchNormalization()(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n#     conv2 =  Dropout(0.2)(conv2)\n    conv2 = BatchNormalization()(conv2)\n#     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n#     conv2 = BatchNormalization()(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n#     conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n#     conv3 = BatchNormalization()(conv3)\n    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n#     conv3 =  Dropout(0.2)(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n#     conv4 =  Dropout(0.2)(conv4)\n    conv4 = BatchNormalization()(conv4)\n#     conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n#     conv4 = BatchNormalization()(conv4)\n    return conv4\n\ndef decoder(conv4):    \n    #decoder\n    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\n#     conv5 =  Dropout(0.2)(conv5)\n    conv5 = BatchNormalization()(conv5)\n#     conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n#     conv5 = BatchNormalization()(conv5)\n    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) #7 x 7 x 64\n#     conv6 =  Dropout(0.2)(conv6)\n    conv6 = BatchNormalization()(conv6)\n#     conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n#     conv6 = BatchNormalization()(conv6)\n    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n#     conv7 =  Dropout(0.2)(conv7)\n    conv7 = BatchNormalization()(conv7)\n#     conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n#     conv7 = BatchNormalization()(conv7)\n    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n    return decoded","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:07:44.720339Z","iopub.execute_input":"2021-10-27T15:07:44.721107Z","iopub.status.idle":"2021-10-27T15:07:44.734564Z","shell.execute_reply.started":"2021-10-27T15:07:44.721055Z","shell.execute_reply":"2021-10-27T15:07:44.73359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Dense,UpSampling2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras import regularizers\nfrom matplotlib import pyplot\nfrom tensorflow.keras.optimizers import Adadelta, RMSprop,SGD,Adam\n\n# define dataset\ninput_img = Input(shape = (32,32,3))\nautoencoder = Model(input_img, decoder(encoder(input_img)))\nautoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T12:19:16.581169Z","iopub.execute_input":"2021-11-02T12:19:16.581531Z","iopub.status.idle":"2021-11-02T12:19:16.945854Z","shell.execute_reply.started":"2021-11-02T12:19:16.581496Z","shell.execute_reply":"2021-11-02T12:19:16.944385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# X_train, X_test, y_train, y_test = train_test_split(train_full_set, train_full_set, test_size=0.33, random_state=1)\n# autoencoder_train = autoencoder.fit(X_train, y_train, batch_size=128,epochs=100,verbose=1,validation_data=(X_test, y_test))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T15:07:57.375317Z","iopub.execute_input":"2021-10-27T15:07:57.375947Z","iopub.status.idle":"2021-10-27T16:14:24.085967Z","shell.execute_reply.started":"2021-10-27T15:07:57.375915Z","shell.execute_reply":"2021-10-27T16:14:24.084977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fc(enco):\n    flat = Flatten()(enco)\n    den = Dense(128, activation='relu')(flat)\n#     den = Dense(128, activation='relu')(den)\n    out = Dense(29, activation='softmax')(den)\n    return out","metadata":{"execution":{"iopub.status.busy":"2021-10-27T16:30:28.100184Z","iopub.execute_input":"2021-10-27T16:30:28.100835Z","iopub.status.idle":"2021-10-27T16:30:28.107453Z","shell.execute_reply.started":"2021-10-27T16:30:28.100778Z","shell.execute_reply":"2021-10-27T16:30:28.106691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# autoencoder.save_weights('autoencoder.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T16:14:50.44313Z","iopub.execute_input":"2021-10-27T16:14:50.443595Z","iopub.status.idle":"2021-10-27T16:14:50.499255Z","shell.execute_reply.started":"2021-10-27T16:14:50.443541Z","shell.execute_reply":"2021-10-27T16:14:50.498359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode = encoder(input_img)\n# full_model = Model(input_img,fc(encode))\n# for l1,l2 in zip(full_model.layers[:10],autoencoder.layers[0:10]):\n#     l1.set_weights(l2.get_weights())","metadata":{"execution":{"iopub.status.busy":"2021-10-27T16:30:33.997895Z","iopub.execute_input":"2021-10-27T16:30:33.998618Z","iopub.status.idle":"2021-10-27T16:30:34.123617Z","shell.execute_reply.started":"2021-10-27T16:30:33.998577Z","shell.execute_reply":"2021-10-27T16:30:34.122943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for layer in full_model.layers[0:10]:\n#     layer.trainable = False\n# full_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T16:30:37.868727Z","iopub.execute_input":"2021-10-27T16:30:37.869357Z","iopub.status.idle":"2021-10-27T16:30:37.879431Z","shell.execute_reply.started":"2021-10-27T16:30:37.869325Z","shell.execute_reply":"2021-10-27T16:30:37.878674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train,X_test,y_train,y_test = train_test_split(train_full_set, train_full_labels,test_size=0.2,random_state=13)\n\n# classify_train = full_model.fit(X_train,y_train, batch_size=64,epochs=100,verbose=1,validation_data=(X_test, y_test))\n# # # ","metadata":{"execution":{"iopub.status.busy":"2021-10-27T16:30:43.266864Z","iopub.execute_input":"2021-10-27T16:30:43.267166Z","iopub.status.idle":"2021-10-27T16:38:26.645084Z","shell.execute_reply.started":"2021-10-27T16:30:43.267134Z","shell.execute_reply":"2021-10-27T16:38:26.643938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_X,valid_X,train_label,valid_label = train_test_split(train_full_set, train_full_labels,test_size=0.2,random_state=13)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = 16\nresize_and_rescale = tf.keras.Sequential([\n  tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE),\n  tf.keras.layers.Rescaling(1./255)\n])\n\ndata_augmentation = tf.keras.Sequential([\n  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n  tf.keras.layers.RandomRotation(0.2),\n    \n])","metadata":{"execution":{"iopub.status.busy":"2021-11-03T15:38:43.525495Z","iopub.execute_input":"2021-11-03T15:38:43.526212Z","iopub.status.idle":"2021-11-03T15:38:43.555445Z","shell.execute_reply.started":"2021-11-03T15:38:43.526153Z","shell.execute_reply":"2021-11-03T15:38:43.554667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nAUTOTUNE = tf.data.AUTOTUNE\n\ndef prepare(ds, shuffle=False, augment=True):\n  # Resize and rescale all datasets.\n  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n              num_parallel_calls=AUTOTUNE)\n\n  if shuffle:\n    ds = ds.shuffle(1000)\n\n  # Batch all datasets.\n  ds = ds.batch(batch_size)\n\n  # Use data augmentation only on the training set.\n  if augment:\n    ds = ds.map(lambda x, y: (data_augmentation(x, training=True), y), \n                num_parallel_calls=AUTOTUNE)\n\n  # Use buffered prefetching on all datasets.\n  return ds.prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-11-03T15:39:01.649503Z","iopub.execute_input":"2021-11-03T15:39:01.649861Z","iopub.status.idle":"2021-11-03T15:39:01.65698Z","shell.execute_reply.started":"2021-11-03T15:39:01.649824Z","shell.execute_reply":"2021-11-03T15:39:01.656002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(train_full_set, train_full_labels,stratify=train_full_labels, test_size=0.3,random_state=13)\nX_train = prepare(X_train)\nX_test = prepare(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-03T15:39:41.300392Z","iopub.execute_input":"2021-11-03T15:39:41.300874Z","iopub.status.idle":"2021-11-03T15:39:41.483469Z","shell.execute_reply.started":"2021-11-03T15:39:41.300839Z","shell.execute_reply":"2021-11-03T15:39:41.48235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Designing Model Architecture l-net 5\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,Rescaling,Resizing,RandomFlip,RandomRotation,Activation,ReLU, MaxPooling2D,AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense , Flatten\n\n# def create_model(optimizer='adam', kernel_initializer='he_normal', activation='relu'):\n# create model\nX_train,X_test,y_train,y_test = train_test_split(train_full_set, train_full_labels,stratify=train_full_labels, test_size=0.3,random_state=13)\n\nmodel = Sequential()\n# model.add(Resizing(16, 16))\nmodel.add(Rescaling(1./255))\n# model.add(RandomFlip(\"horizontal_and_vertical\"))\n# model.add(RandomRotation(0.2))\nmodel.add(Conv2D(filters=64, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same', input_shape=(32,32,3)))\nmodel.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\nmodel.add(ReLU())\n# model.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\nmodel.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\nmodel.add(ReLU())\n\n# model.add(Conv2D(filters=128, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\n# model.add(Conv2D(filters=128, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(filters=128, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\nmodel.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\nmodel.add(ReLU())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n\n# model.add(Conv2D(filters=128, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\nmodel.add(Conv2D(filters=256, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\nmodel.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\nmodel.add(ReLU())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n\n\n# model.add(Conv2D(filters=256, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\n# model.add(Conv2D(filters=256, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\n# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# model.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=512, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='valid'))\nmodel.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\nmodel.add(ReLU())\n\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n# not needed\n# model.add(Conv2D(filters=2048, kernel_size=1,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='valid'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\n# model.add(Conv2D(filters=256, kernel_size=1,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='valid'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\n# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n# model.add(Dropout(0.2))\n\n# model.add(Conv2D(filters=256, kernel_size=3,kernel_initializer='glorot_uniform',  strides=(1, 1), padding='same'))\n# model.add(BatchNormalization(epsilon=1e-05, momentum=0.05))\n# model.add(ReLU())\n\n#Fully connected final layer\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\n# model.add(Dense(84, activation='relu'))\nmodel.add(Dense(29, activation='softmax'))\n\n# Compile model\nmodel.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n# return model\n\nmodel.fit(X_train, y_train, \n                validation_data=(X_test, y_test),\n                epochs=70, batch_size=32, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T15:28:27.035121Z","iopub.execute_input":"2021-11-04T15:28:27.035463Z","iopub.status.idle":"2021-11-04T15:28:51.425225Z","shell.execute_reply.started":"2021-11-04T15:28:27.035402Z","shell.execute_reply":"2021-11-04T15:28:51.423953Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/70\n 81/294 [=======>......................] - ETA: 59s - loss: 2.4794 - accuracy: 0.2654","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2944993352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m model.fit(X_train, y_train, \n\u001b[1;32m     98\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 epochs=70, batch_size=32, verbose=1)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T13:26:33.586105Z","iopub.execute_input":"2021-11-04T13:26:33.586595Z","iopub.status.idle":"2021-11-04T13:26:33.611860Z","shell.execute_reply.started":"2021-11-04T13:26:33.586561Z","shell.execute_reply":"2021-11-04T13:26:33.610958Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_8 (Conv2D)            (None, 32, 32, 64)        1792      \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 32, 32, 64)        256       \n_________________________________________________________________\nre_lu_8 (ReLU)               (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 32, 32, 128)       73856     \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 32, 32, 128)       512       \n_________________________________________________________________\nre_lu_9 (ReLU)               (None, 32, 32, 128)       0         \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 16, 16, 128)       0         \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 16, 16, 128)       147584    \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 16, 16, 128)       512       \n_________________________________________________________________\nre_lu_10 (ReLU)              (None, 16, 16, 128)       0         \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 8, 8, 128)         0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 8, 8, 128)         0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 8, 8, 256)         295168    \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 8, 8, 256)         1024      \n_________________________________________________________________\nre_lu_11 (ReLU)              (None, 8, 8, 256)         0         \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 4, 4, 256)         0         \n_________________________________________________________________\ndropout_8 (Dropout)          (None, 4, 4, 256)         0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 2, 2, 512)         1180160   \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n_________________________________________________________________\nre_lu_12 (ReLU)              (None, 2, 2, 512)         0         \n_________________________________________________________________\nmax_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n_________________________________________________________________\ndropout_9 (Dropout)          (None, 1, 1, 512)         0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndense_5 (Dense)              (None, 29)                14877     \n=================================================================\nTotal params: 1,980,445\nTrainable params: 1,978,269\nNon-trainable params: 2,176\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"y_preds_classes = np.argmax(model.predict(train_full_set), axis=-1)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-02T19:35:20.026516Z","iopub.execute_input":"2021-11-02T19:35:20.026888Z","iopub.status.idle":"2021-11-02T19:36:50.187683Z","shell.execute_reply.started":"2021-11-02T19:35:20.026844Z","shell.execute_reply":"2021-11-02T19:36:50.18653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels['pred']=  y_preds_classes","metadata":{"execution":{"iopub.status.busy":"2021-11-02T19:41:06.407051Z","iopub.execute_input":"2021-11-02T19:41:06.407666Z","iopub.status.idle":"2021-11-02T19:41:06.412246Z","shell.execute_reply.started":"2021-11-02T19:41:06.407626Z","shell.execute_reply":"2021-11-02T19:41:06.411498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(train_labels['label'],train_labels['pred'])","metadata":{"execution":{"iopub.status.busy":"2021-11-02T19:46:11.754095Z","iopub.execute_input":"2021-11-02T19:46:11.755112Z","iopub.status.idle":"2021-11-02T19:46:11.764221Z","shell.execute_reply.started":"2021-11-02T19:46:11.755064Z","shell.execute_reply":"2021-11-02T19:46:11.763106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Designing Model Architecture l-net 5\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense , Flatten\n\n# def create_model(optimizer='adam', kernel_initializer='he_normal', activation='relu'):\n# create model\nX_train,X_test,y_train,y_test = train_test_split(train_full_set, train_full_labels,stratify=train_full_labels, test_size=0.3,random_state=13)\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=6, kernel_size=5, padding='valid', input_shape=(32,32,3), activation='relu'))\n# model.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(MaxPooling2D(pool_size=2))\n\n\nmodel.add(Conv2D(filters=16, kernel_size=3, padding='valid', activation='relu'))\n# model.add(BatchNormalization())\nmodel.add(Dropout(0.2))\n# model.add(Conv2D(filters=32, kernel_size=5, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters=32, kernel_size=3, padding='valid', activation='relu'))\nmodel.add(Dropout(0.2))\n# model.add(Dropout(0.2))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\nmodel.add(Dropout(0.2))\n# model.add(Dropout(0.2))\nmodel.add(MaxPooling2D(pool_size=2))\n\n# model.add(Conv2D(filters=120, kernel_size=5, padding='same', activation='relu'))\n# # model.add(BatchNormalization())\n# model.add(Dropout(0.4))\n\n# model.add(MaxPooling2D(pool_size=2))\n# model.add(Dropout(0.2))\n\n# model.add(Conv2D(filters=120, kernel_size=5, padding='same', activation='relu'))\n# model.add(BatchNormalization())\n# model.add(AveragePooling2D(pool_size=2))\n# model.add(Dropout(0.2))\n# model.add(GlobalAveragePooling2D())\nmodel.add(Conv2D(filters=, kernel_size=1, padding='same', activation='relu'))\n\n#Fully connected final layer\n# model.add(Flatten())\n# model.add(Dense(120, activation='relu'))\nmodel.add(Dense(84, activation='relu'))\nmodel.add(Dense(29, activation='softmax'))\n\n# Compile model\nmodel.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n# return model\n\n# model.fit(X_train, y_train, \n#                 validation_data=(X_test, y_test),\n#                 epochs=100, batch_size=128, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:45:09.802805Z","iopub.execute_input":"2021-11-01T13:45:09.803941Z","iopub.status.idle":"2021-11-01T13:45:10.022429Z","shell.execute_reply.started":"2021-11-01T13:45:09.80387Z","shell.execute_reply":"2021-11-01T13:45:10.021698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T13:45:11.051963Z","iopub.execute_input":"2021-11-01T13:45:11.052611Z","iopub.status.idle":"2021-11-01T13:45:11.064477Z","shell.execute_reply.started":"2021-11-01T13:45:11.052564Z","shell.execute_reply":"2021-11-01T13:45:11.063576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Model Summary And Visualization\n\n# model = create_model()\n# # model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T14:41:30.557329Z","iopub.status.idle":"2021-10-27T14:41:30.558169Z","shell.execute_reply.started":"2021-10-27T14:41:30.557878Z","shell.execute_reply":"2021-10-27T14:41:30.557909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Designing Model Architecture\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense , Flatten\nX_train,X_test,y_train,y_test = train_test_split(train_full_set, train_full_labels,test_size=0.2,random_state=13)\n\n# def create_model(optimizer='adam', kernel_initializer='he_normal', activation='relu'):\n# create model\nmodel = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=3, padding='same', input_shape=(32,32,1), kernel_initializer='he_normal', activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\n\n\nmodel.add(Conv2D(filters=32, kernel_size=3, padding='same', kernel_initializer='he_normal', activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\n# model.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=64, kernel_size=3, padding='same', kernel_initializer='he_normal', activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\n# model.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal', activation='relu'))\nmodel.add(Dropout(0.4))\n# model.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=2))\n# model.add(Dropout(0.2))\n# model.add(GlobalAveragePooling2D())\n\n#Fully connected final layer\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(29, activation='softmax'))\n\n# Compile model\nmodel.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='Adam')\n# return model\n\nmodel.fit(X_train, y_train, \n                validation_data=(X_test, y_test),\n                epochs=100, batch_size=64, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T19:33:54.111254Z","iopub.execute_input":"2021-10-27T19:33:54.111528Z","iopub.status.idle":"2021-10-27T19:35:00.317814Z","shell.execute_reply.started":"2021-10-27T19:33:54.111502Z","shell.execute_reply":"2021-10-27T19:35:00.316512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://pypi.python.org/pypi/pydot\n!apt-get -qq install -y graphviz && pip install -q pydot\nimport pydot","metadata":{"execution":{"iopub.status.busy":"2021-10-24T21:39:08.89033Z","iopub.execute_input":"2021-10-24T21:39:08.890663Z","iopub.status.idle":"2021-10-24T21:39:21.866202Z","shell.execute_reply.started":"2021-10-24T21:39:08.890628Z","shell.execute_reply":"2021-10-24T21:39:21.865317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\n\nplot_model(model, to_file=\"model.png\", show_shapes=True)\nfrom IPython.display import Image as IPythonImage\ndisplay(IPythonImage('model.png'))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T22:12:37.618897Z","iopub.execute_input":"2021-10-24T22:12:37.619236Z","iopub.status.idle":"2021-10-24T22:12:38.982044Z","shell.execute_reply.started":"2021-10-24T22:12:37.619201Z","shell.execute_reply":"2021-10-24T22:12:38.980944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Parameters Tuning\n# We will tune the parameters optimizer, kernel_initializer and activation.\n\n# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)\n\n# define the grid search parameters\noptimizer = ['RMSprop', 'Adam', 'Adagrad', 'Nadam']\nkernel_initializer = ['normal', 'uniform']\nactivation = ['relu', 'linear', 'tanh']\n\nparam_grid = dict(optimizer=optimizer, kernel_initializer=kernel_initializer, activation=activation)\n\n# count number of different parameters values combinations\nparameters_number = 1\nfor x in param_grid:\n  parameters_number = parameters_number * len(param_grid[x]) \nprint(\"Number of different parameter combinations = {}\".format(parameters_number))","metadata":{"execution":{"iopub.status.busy":"2021-10-24T22:12:45.292517Z","iopub.execute_input":"2021-10-24T22:12:45.292809Z","iopub.status.idle":"2021-10-24T22:12:45.301047Z","shell.execute_reply.started":"2021-10-24T22:12:45.292776Z","shell.execute_reply":"2021-10-24T22:12:45.30027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# # We will try different models with different parameters to find the best parameter values.\n\n# epochs = 5\n# batch_size = 20 # 20 divides the training data samples\n\n# #creating the models with different hyperparameters\n# for a,b,c in [(x,y,z) for x in optimizer for z in activation for y in kernel_initializer]:\n#     params = {'optimizer' : a , 'kernel_initializer' : b , 'activation' : c}\n#     print(params)\n#     curr_model = create_model(a, b, c)\n#     curr_model.fit(X_train, y_train, \n#                     validation_data=(X_valid, y_valid),\n#                     epochs=epochs, batch_size=batch_size, verbose=1)\n#     print(\"=============================================================================\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T15:22:06.652609Z","iopub.execute_input":"2021-11-04T15:22:06.653130Z","iopub.status.idle":"2021-11-04T15:22:06.657687Z","shell.execute_reply.started":"2021-11-04T15:22:06.653086Z","shell.execute_reply":"2021-11-04T15:22:06.656623Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu',input_shape=(32, 32, 3)),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', ),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    \n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(29, activation='softmax')\n \n])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:59:00.298861Z","iopub.execute_input":"2021-10-24T08:59:00.299284Z","iopub.status.idle":"2021-10-24T08:59:00.371383Z","shell.execute_reply.started":"2021-10-24T08:59:00.29925Z","shell.execute_reply":"2021-10-24T08:59:00.370311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nearly_stopp = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:59:00.372628Z","iopub.execute_input":"2021-10-24T08:59:00.372898Z","iopub.status.idle":"2021-10-24T08:59:00.386477Z","shell.execute_reply.started":"2021-10-24T08:59:00.372868Z","shell.execute_reply":"2021-10-24T08:59:00.385571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), \n                    epochs=10, batch_size=32, callbacks=[early_stopp])","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:59:00.388026Z","iopub.execute_input":"2021-10-24T08:59:00.388619Z","iopub.status.idle":"2021-10-24T08:59:32.957369Z","shell.execute_reply.started":"2021-10-24T08:59:00.388569Z","shell.execute_reply":"2021-10-24T08:59:32.956296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(history.history).plot(figsize=(10, 6));","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:59:32.958841Z","iopub.execute_input":"2021-10-24T08:59:32.959071Z","iopub.status.idle":"2021-10-24T08:59:33.234117Z","shell.execute_reply.started":"2021-10-24T08:59:32.959043Z","shell.execute_reply":"2021-10-24T08:59:33.233343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_all_data, acc_all_data = model.evaluate(train_full_set, train_full_labels, verbose=0)\nprint('loss_all_data =>', loss_all_data)\nprint('acc_all_data =>', acc_all_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-24T08:59:33.235163Z","iopub.execute_input":"2021-10-24T08:59:33.235957Z","iopub.status.idle":"2021-10-24T08:59:34.74403Z","shell.execute_reply.started":"2021-10-24T08:59:33.23592Z","shell.execute_reply":"2021-10-24T08:59:34.743394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_labels = pd.read_csv('../input/arabic-hwr-ai-pro-intake1/test.csv')\ntest_images = Path(r'../input/arabic-hwr-ai-pro-intake1/test')\n\n## read these all training images paths as Series\ntest_images_paths = pd.Series(sorted(list(test_images.glob(r'*.png'))), name='Filepath').astype(str)\n\ntest_images_paths.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T15:22:14.960945Z","iopub.execute_input":"2021-11-04T15:22:14.961256Z","iopub.status.idle":"2021-11-04T15:22:15.098518Z","shell.execute_reply.started":"2021-11-04T15:22:14.961224Z","shell.execute_reply":"2021-11-04T15:22:15.097849Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"0    ../input/arabic-hwr-ai-pro-intake1/test/00000.png\n1    ../input/arabic-hwr-ai-pro-intake1/test/00001.png\n2    ../input/arabic-hwr-ai-pro-intake1/test/00002.png\n3    ../input/arabic-hwr-ai-pro-intake1/test/00003.png\n4    ../input/arabic-hwr-ai-pro-intake1/test/00004.png\nName: Filepath, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"print('Number of Instances in test_set is', len(test_images_paths))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:14:03.506529Z","iopub.execute_input":"2021-10-27T18:14:03.50706Z","iopub.status.idle":"2021-10-27T18:14:03.51289Z","shell.execute_reply.started":"2021-10-27T18:14:03.507025Z","shell.execute_reply":"2021-10-27T18:14:03.512177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_full_set = np.empty((3360, 32, 32, 3), dtype=np.float32)  #take only the first 3 channels\n\nfor idx, path in enumerate(test_images_paths):\n    img = cv2.imread(path)\n    img = img[:,:,:3]\n#     img = cv2.dilate(img,(5,5)) \n#     img3_gr = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n#     im_e,binary = cv2.threshold(img3_gr,100,100,cv2.THRESH_BINARY_INV)\n#     img = img/img.max()\n    test_full_set[idx] = img\n    \nprint('test_full_set.shape =>', test_full_set.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T15:22:26.289731Z","iopub.execute_input":"2021-11-04T15:22:26.289984Z","iopub.status.idle":"2021-11-04T15:22:43.508819Z","shell.execute_reply.started":"2021-11-04T15:22:26.289958Z","shell.execute_reply":"2021-11-04T15:22:43.507499Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"test_full_set.shape => (3360, 32, 32, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"y_preds_classes = np.argmax(model.predict(test_full_set), axis=-1)\ntest_labels['label'] = y_preds_classes","metadata":{"execution":{"iopub.status.busy":"2021-11-04T15:23:12.843955Z","iopub.execute_input":"2021-11-04T15:23:12.844271Z","iopub.status.idle":"2021-11-04T15:23:21.797271Z","shell.execute_reply.started":"2021-11-04T15:23:12.844237Z","shell.execute_reply":"2021-11-04T15:23:21.795807Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_labels[['label']].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T15:23:22.478920Z","iopub.execute_input":"2021-11-04T15:23:22.479174Z","iopub.status.idle":"2021-11-04T15:23:22.499899Z","shell.execute_reply.started":"2021-11-04T15:23:22.479151Z","shell.execute_reply":"2021-11-04T15:23:22.498498Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"label\n10       130\n22       128\n3        124\n16       124\n4        123\n1        121\n2        121\n27       121\n20       121\n19       121\n15       121\n6        121\n12       120\n13       120\n5        120\n11       119\n24       119\n23       119\n21       119\n7        118\n18       118\n14       118\n17       117\n26       117\n8        116\n28       116\n9        114\n25       114\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"\nplt.imshow()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_key_value = {}\nfor value in test_labels['label'].unique():\n    img_key_value[value] = test_labels[test_labels['label']==value].index[0]\n    \nimg_index = list(img_key_value.values())\nimg_label = list(img_key_value.keys())\n\nfig, ax = plt.subplots(4, 7, figsize=(12, 8))\n\ni = 0\nfor row in range(4):\n    for col in range(7):\n        plt.sca(ax[row, col])\n        plt.title(f'label = {i}')\n        img = plt.imread(test_images_paths.iloc[i])\n        plt.imshow(img[:,:,:3])\n        plt.axis('off')\n        i+=1","metadata":{"execution":{"iopub.status.busy":"2021-11-03T18:51:33.740461Z","iopub.execute_input":"2021-11-03T18:51:33.740936Z","iopub.status.idle":"2021-11-03T18:51:34.953569Z","shell.execute_reply.started":"2021-11-03T18:51:33.740887Z","shell.execute_reply":"2021-11-03T18:51:34.952753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_labels[['id', 'label']].to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T15:23:55.832439Z","iopub.execute_input":"2021-11-04T15:23:55.832696Z","iopub.status.idle":"2021-11-04T15:23:55.844117Z","shell.execute_reply.started":"2021-11-04T15:23:55.832672Z","shell.execute_reply":"2021-11-04T15:23:55.841948Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}